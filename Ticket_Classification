!pip install fasttext nltk sentence-transformers

import pandas as pd
import numpy as np
import random
from nltk.corpus import wordnet
from sklearn.model_selection import train_test_split
import fasttext
from sentence_transformers import SentenceTransformer, util

# Download NLTK data
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')

file_path = "/content/all_tickets_processed_improved_v3.csv"
data = pd.read_csv(file_path)

print("Dataset Head:")
print(data.head())
print("\nDataset Info:")
print(data.info())

data.columns = ['Document', 'Topic_group']

# Strip leading/trailing whitespaces
data['Document'] = data['Document'].str.strip()
data['Topic_group'] = data['Topic_group'].str.strip()

# Save labels in FastText format: `__label__<Topic_group> <Document>`
data['fasttext_format'] = data['Topic_group'].apply(lambda x: f"__label__{x} ") + data['Document']

# Split the data: 80% train, 20% test
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

test_file = "test.txt"
test_data['fasttext_format'].to_csv(test_file, index=False, header=False)

print(f"Testing data saved to: {test_file}")


# Function to replace words with synonyms
def replace_with_synonyms(text, num_replacements=1):
    words = text.split()
    for _ in range(num_replacements):
        word_idx = random.randint(0, len(words) - 1)
        synonyms = wordnet.synsets(words[word_idx])
        if synonyms:
            synonym = synonyms[0].lemmas()[0].name()
            words[word_idx] = synonym
    return ' '.join(words)

# Apply synonym replacement
synonym_augmented = train_data.copy()
synonym_augmented['Document'] = synonym_augmented['Document'].apply(lambda x: replace_with_synonyms(x))

# Combine original and synonym-augmented data
final_train_data = pd.concat([train_data, synonym_augmented]).reset_index(drop=True)

# Save the combined training data
final_train_file = "final_train.txt"
final_train_data['fasttext_format'] = final_train_data['Topic_group'].apply(lambda x: f"__label__{x} ") + final_train_data['Document']
final_train_data['fasttext_format'].to_csv(final_train_file, index=False, header=False)

print(f"Augmented training data saved to: {final_train_file}")


# Train the FastText model
model = fasttext.train_supervised(input=final_train_file, epoch=25, lr=0.1, wordNgrams=2)

# Save the trained model
model_file = "fasttext_ticket_classifier_augmented.bin"
model.save_model(model_file)

print(f"Model trained and saved to: {model_file}")


# Evaluate the model on the test set
results = model.test(test_file)

# Extract evaluation metrics
num_samples = results[0]  # Total number of samples
precision = results[1]    # Precision
recall = results[2]       # Recall
accuracy = precision       # Accuracy is equivalent to precision

# Display the evaluation results
print("Evaluation Results:")
print(f"Total Samples: {num_samples}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Accuracy: {accuracy:.4f}")

# Count of each ticket type
ticket_type_counts = data['Topic_group'].value_counts()

# Pie chart
plt.figure(figsize=(8, 8))
ticket_type_counts.plot.pie(autopct='%1.1f%%', startangle=140, cmap='viridis')
plt.title('Ticket Type Distribution')
plt.ylabel('')
plt.show()

# Bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x=ticket_type_counts.index, y=ticket_type_counts.values, palette="viridis")
plt.title('Ticket Type Distribution')
plt.ylabel('Count')
plt.xlabel('Ticket Type')
plt.xticks(rotation=45, ha='right')
plt.show()
